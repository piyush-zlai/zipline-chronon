package build.cloud_aws
import mill._
import mill.scalalib._

// Cloud AWS module
object `package` extends build.BaseModule {
  def moduleDeps = Seq(build.spark, build.aggregator, build.api, build.online)

  def mvnDeps = build.Constants.commonDeps ++ build.Constants.loggingApiDeps ++ build.Constants.utilityDeps ++ build.Constants.sparkDeps ++ Seq(
    mvn"software.amazon.awssdk:dynamodb:2.30.13",
    mvn"software.amazon.awssdk:emr:2.30.13",
    mvn"software.amazon.awssdk:regions:2.30.13",
    mvn"software.amazon.awssdk:aws-core:2.30.13",
    mvn"software.amazon.awssdk:sdk-core:2.30.13",
    mvn"software.amazon.awssdk:utils:2.30.13",
    mvn"software.amazon.awssdk:auth:2.30.13",
    mvn"software.amazon.awssdk:url-connection-client:2.30.13",
    mvn"software.amazon.awssdk:identity-spi:2.30.13",
    mvn"org.apache.hudi::hudi-spark3.5-bundle:1.0.0",
  )
  
  object test extends build.BaseTestModule {
    def moduleDeps = Seq(build.cloud_aws, build.spark.test)
    def mvnDeps = Seq(
      mvn"org.testcontainers:testcontainers:1.19.3",
      mvn"org.testcontainers:junit-jupiter:1.19.3"
    )
    override def testFramework = "org.scalatest.tools.Framework"
    def forkArgs = build.Constants.commonTestForkArgs ++ Seq(
      "-Dspark.sql.adaptive.enabled=false",
      "-Dspark.sql.adaptive.coalescePartitions.enabled=false",
      "-Dspark.serializer=org.apache.spark.serializer.KryoSerializer",
      "-Dspark.sql.hive.convertMetastoreParquet=false"
    )
  }

  def prependShellScript = ""
}